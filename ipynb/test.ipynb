{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35b07857-28b9-40f4-8cab-67246428d212",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_en = \"NLP makes it possible for machines to understand human language.\"\n",
    "text_ko = \"자연어처리는 기계가 인간의 언어를 이해하도록 만드는 기술입니다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "210cfaa4-576d-4750-b770-e8048152906d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN (split): ['NLP', 'makes', 'it', 'possible', 'for', 'machines', 'to', 'understand', 'human', 'language.']\n",
      "KO (split): ['자연어처리는', '기계가', '인간의', '언어를', '이해하도록', '만드는', '기술입니다.']\n"
     ]
    }
   ],
   "source": [
    "# 기본 파이썬 토큰화 (공벡기준)\n",
    "print(\"EN (split):\", text_en.split())\n",
    "print(\"KO (split):\", text_ko.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "651b96d7-1c8b-420a-82c6-3d37bf0bd81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk #토큰화, 형태소 분석, 품사 태깅, 파싱, 의미 분석, 텍스트 분류 등 다양한 NLP 기능을 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80ffcc15-f949-4619-904f-db40680119a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/parkjuyong/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d8bd5d9-496a-4b47-9e31-56669ad3a509",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/parkjuyong/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bec6288-6809-4a0d-87d5-460d0a9c59bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8c84555-314c-42b0-a256-7809ff9eb0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLP', 'makes', 'it', 'possible', 'for', 'machines', 'to', 'understand', 'human', 'language', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(text_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ea53193-3672-4684-a185-2a55a6b6519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fd920fe-a9d4-419a-9afe-84ef10c5baac",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca2c9669-08df-4f96-b0c3-1d4f4ba50a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "morphs: ['자연어', '처리', '는', '정말', '재미있고', '유용한', '분야', '입니다', '.']\n",
      "nouns: ['자연어', '처리', '정말', '분야']\n",
      "pos: [('자연어', 'Noun'), ('처리', 'Noun'), ('는', 'Josa'), ('정말', 'Noun'), ('재미있고', 'Adjective'), ('유용한', 'Adjective'), ('분야', 'Noun'), ('입니다', 'Adjective'), ('.', 'Punctuation')]\n"
     ]
    }
   ],
   "source": [
    "print(\"morphs:\", okt.morphs(\"자연어처리는 정말 재미있고 유용한 분야입니다.\")) # 한국어 문장을 형태소 단위로 분리\n",
    "print(\"nouns:\", okt.nouns(\"자연어처리는 정말 재미있고 유용한 분야입니다.\")) # 문장에서 명사만 추출 (형태소 분석 -> 명사 추출 flow)\n",
    "print(\"pos:\", okt.pos(\"자연어처리는 정말 재미있고 유용한 분야입니다.\")) # 형태소 단위 + 품사 태깅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff6febc9-8704-4fc8-a625-8c4c46de1c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e35d1b09-a30e-439a-93b2-aba889cc392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = AutoTokenizer.from_pretrained(\"klue/bert-base\") # BERT 기반 토크나이저 (한국어용 kule/bert-base)\n",
    "# WordPiece 토크나이저를 사용 -> 내부적으로 BertTokenizerFast를 불러와서 WordPiece 알고리즘을 적용\n",
    "# 동작 방식\n",
    "# 1. 어휘집(모델 학습 시 사용하는 고정 어휘집)불러오기\n",
    "# 2. 텍스트 전처리(소문자 변환(옵션), 공백 기준으로 먼저 쪼갬, 특수기호, 숫자 등도 분리)\n",
    "# 3. 단어 → 서브워드(Subword) 분리 (사전에 없는 단어를 처리 하기 위해서(OOV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aa03779-a2fd-4b09-9a8c-930884c233db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['자연', '##어', '##처리', '##는', '정말', '재미', '##잇', '##고', '유용', '##한', '분야', '##입니다', '.']\n",
      "['Un', '##be', '##l', '##ie', '##v', '##ab', '##ly', 'st', '##ron', '##g', 'per', '##form', '##ance', 'on', 'l', '##ow', '-', 'res', '##our', '##ce', 't', '##as', '##k', '.']\n"
     ]
    }
   ],
   "source": [
    "print(tok.tokenize(\"자연어처리는 정말 재미잇고 유용한 분야입니다.\"))\n",
    "print(tok.tokenize(\"Unbelievably strong performance on low-resource task.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "182c5a0c-f39e-4c51-8706-e32da089a0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "780a6f90-31be-42bf-977d-c930d0bd698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\") # 영어 NLP 전처리 + 토큰화, 품사, 개체명 인식 등\n",
    "doc = nlp(\"NLP makes it possible for machines to understand human language.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80671795-6e09-48b7-88f7-428a8b6307fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NLP', 'PROPN', 'NNP'),\n",
       " ('makes', 'VERB', 'VBZ'),\n",
       " ('it', 'PRON', 'PRP'),\n",
       " ('possible', 'ADJ', 'JJ'),\n",
       " ('for', 'SCONJ', 'IN'),\n",
       " ('machines', 'NOUN', 'NNS'),\n",
       " ('to', 'PART', 'TO'),\n",
       " ('understand', 'VERB', 'VB'),\n",
       " ('human', 'ADJ', 'JJ'),\n",
       " ('language', 'NOUN', 'NN'),\n",
       " ('.', 'PUNCT', '.')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(t.text, t.pos_, t.tag_) for t in doc]\n",
    "# text : spaCy 규칙 기반 토큰화\n",
    "# pos_ : Universal POS Tag : 언어 불문 공통 품사 태그셋 사용 (태그 수가 적고 범용적)\n",
    "# tag_ : Language-Specific POS Tag : 언어별 세부적인 품사 태그셋 사용(pos_ 보다 세밀한 구분 가능 → 구문 분석, 의존 구문 트리, 정밀한 NLP 작업에 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572ff5e3-5e8b-48df-96d9-d83fdd7298c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP\n(NLP_Lec_env)",
   "language": "python",
   "name": "nlp_lec_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
